"""
Tests for Batch Processor module.
"""

import pytest
from unittest.mock import Mock, patch, AsyncMock
from src.blog_writer_sdk.batch.batch_processor import BatchProcessor
from src.blog_writer_sdk.models.blog_models import BlogRequest, ContentTone, ContentLength


class TestBatchProcessor:
    """Test cases for BatchProcessor class."""
    
    @pytest.fixture
    def mock_blog_writer(self):
        """Create a mock blog writer."""
        return Mock()
    
    @pytest.fixture
    def batch_processor(self, mock_blog_writer):
        """Create BatchProcessor instance with mocked dependencies."""
        return BatchProcessor(mock_blog_writer)
    
    def test_initialization(self, batch_processor, mock_blog_writer):
        """Test BatchProcessor initialization."""
        assert batch_processor.blog_writer == mock_blog_writer
        assert batch_processor.max_concurrent == 5
        assert batch_processor.max_retries == 2
    
    def test_create_batch_job(self, batch_processor):
        """Test creating a batch job."""
        requests = [
            BlogRequest(
                topic="Python Programming",
                keywords=["python", "programming"],
                tone=ContentTone.PROFESSIONAL,
                length=ContentLength.MEDIUM
            ),
            BlogRequest(
                topic="Machine Learning",
                keywords=["ml", "ai"],
                tone=ContentTone.TECHNICAL,
                length=ContentLength.LONG
            )
        ]
        
        job = batch_processor.create_batch_job(requests)
        
        assert job is not None
        assert job.job_id is not None
        assert job.status == "pending"
        assert len(job.requests) == 2
        assert job.total_requests == 2
        assert job.completed_requests == 0
    
    @pytest.mark.asyncio
    async def test_process_batch_job_success(self, batch_processor, mock_blog_writer):
        """Test successful batch job processing."""
        # Mock blog writer to return successful results
        mock_result = Mock()
        mock_result.success = True
        mock_result.blog_post = Mock()
        mock_result.blog_post.title = "Generated Blog Post"
        mock_blog_writer.generate_blog.return_value = mock_result
        
        requests = [
            BlogRequest(
                topic="Python Programming",
                keywords=["python", "programming"],
                tone=ContentTone.PROFESSIONAL,
                length=ContentLength.MEDIUM
            )
        ]
        
        job = batch_processor.create_batch_job(requests)
        result = await batch_processor.process_batch(job.id)
        
        assert result is not None
        assert result.status == "completed"
        assert result.completed_requests == 1
        assert len(result.results) == 1
        assert result.results[0].success is True
    
    @pytest.mark.asyncio
    async def test_process_batch_job_with_failures(self, batch_processor, mock_blog_writer):
        """Test batch job processing with some failures."""
        # Mock blog writer to fail for some requests
        def mock_generate_blog(request):
            if "Python" in request.topic:
                result = Mock()
                result.success = True
                result.blog_post = Mock()
                result.blog_post.title = "Python Blog"
                return result
            else:
                result = Mock()
                result.success = False
                result.error = "Generation failed"
                return result
        
        mock_blog_writer.generate_blog.side_effect = mock_generate_blog
        
        requests = [
            BlogRequest(
                topic="Python Programming",
                keywords=["python"],
                tone=ContentTone.PROFESSIONAL,
                length=ContentLength.MEDIUM
            ),
            BlogRequest(
                topic="Failed Topic",
                keywords=["failed"],
                tone=ContentTone.PROFESSIONAL,
                length=ContentLength.MEDIUM
            )
        ]
        
        job = batch_processor.create_batch_job(requests)
        result = await batch_processor.process_batch(job.id)
        
        assert result is not None
        assert result.status == "completed"
        assert result.completed_requests == 2
        assert len(result.results) == 2
        assert result.results[0].success is True
        assert result.results[1].success is False
    
    @pytest.mark.asyncio
    async def test_process_batch_job_timeout(self, batch_processor, mock_blog_writer):
        """Test batch job processing with timeout."""
        # Mock blog writer to take too long
        async def slow_generate_blog(request):
            await asyncio.sleep(10)  # Simulate slow operation
            result = Mock()
            result.success = True
            return result
        
        mock_blog_writer.generate_blog.side_effect = slow_generate_blog
        
        # Set short timeout for testing
        batch_processor.job_timeout = 1
        
        requests = [
            BlogRequest(
                topic="Slow Topic",
                keywords=["slow"],
                tone=ContentTone.PROFESSIONAL,
                length=ContentLength.MEDIUM
            )
        ]
        
        job = batch_processor.create_batch_job(requests)
        result = await batch_processor.process_batch(job.id)
        
        assert result is not None
        assert result.status == "timeout"
        assert result.completed_requests == 0
    
    def test_get_job_status(self, batch_processor):
        """Test getting job status."""
        requests = [
            BlogRequest(
                topic="Test Topic",
                keywords=["test"],
                tone=ContentTone.PROFESSIONAL,
                length=ContentLength.MEDIUM
            )
        ]
        
        job = batch_processor.create_batch_job(requests)
        status = batch_processor.get_batch_status(job.id)
        
        assert status is not None
        assert status.job_id == job.job_id
        assert status.status == "pending"
    
    def test_get_job_status_not_found(self, batch_processor):
        """Test getting status for non-existent job."""
        status = batch_processor.get_job_status("non-existent-job-id")
        
        assert status is None
    
    def test_cancel_job(self, batch_processor):
        """Test canceling a job."""
        requests = [
            BlogRequest(
                topic="Test Topic",
                keywords=["test"],
                tone=ContentTone.PROFESSIONAL,
                length=ContentLength.MEDIUM
            )
        ]
        
        job = batch_processor.create_batch_job(requests)
        success = batch_processor.cancel_batch_job(job.id)
        
        assert success is True
        
        # Check that job status is updated
        status = batch_processor.get_batch_status(job.id)
        assert status.status == "cancelled"
    
    def test_cancel_job_not_found(self, batch_processor):
        """Test canceling a non-existent job."""
        success = batch_processor.cancel_batch_job("non-existent-job-id")
        
        assert success is False
    
    def test_get_job_history(self, batch_processor):
        """Test getting job history."""
        # Create a few jobs
        requests1 = [BlogRequest(topic="Topic 1", keywords=["test1"], tone=ContentTone.PROFESSIONAL, length=ContentLength.MEDIUM)]
        requests2 = [BlogRequest(topic="Topic 2", keywords=["test2"], tone=ContentTone.PROFESSIONAL, length=ContentLength.MEDIUM)]
        
        job1 = batch_processor.create_batch_job(requests1)
        job2 = batch_processor.create_batch_job(requests2)
        
        history = batch_processor.list_batch_jobs()
        
        assert len(history) >= 2
        job_ids = [job['id'] for job in history]
        assert job1.id in job_ids
        assert job2.id in job_ids
    
    def test_cleanup_completed_jobs(self, batch_processor):
        """Test cleaning up completed jobs."""
        # Create a job
        requests = [BlogRequest(topic="Test Topic", keywords=["test"], tone=ContentTone.PROFESSIONAL, length=ContentLength.MEDIUM)]
        job = batch_processor.create_batch_job(requests)
        
        # Test that we can delete the job
        success = batch_processor.delete_batch_job(job.id)
        assert success is True
        
        # Verify job is no longer accessible
        status = batch_processor.get_batch_status(job.id)
        assert status is None
    
    def test_get_batch_statistics(self, batch_processor):
        """Test getting batch processing statistics."""
        # Create some jobs with different statuses
        requests = [BlogRequest(topic="Test Topic", keywords=["test"], tone=ContentTone.PROFESSIONAL, length=ContentLength.MEDIUM)]
        
        job1 = batch_processor.create_batch_job(requests)
        job1.status = "completed"
        
        job2 = batch_processor.create_batch_job(requests)
        job2.status = "failed"
        
        job3 = batch_processor.create_batch_job(requests)
        job3.status = "pending"
        
        # Jobs are automatically tracked by the batch processor
        
        stats = batch_processor.get_batch_statistics()
        
        assert "total_jobs" in stats
        assert "completed_jobs" in stats
        assert "failed_jobs" in stats
        assert "active_jobs" in stats
        
        assert stats["total_jobs"] >= 3
